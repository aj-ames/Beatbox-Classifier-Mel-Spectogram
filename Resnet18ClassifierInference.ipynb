{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import simpleaudio as sa\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ffpyplayer.player import MediaPlayer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(512),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "file_path = 'runtime_videos/'\n",
    "runtime_path = 'runtime/'\n",
    "model_path = 'models/resnet18_beatbox_classifier.pth'\n",
    "results_dict = dict()\n",
    "genre_list = {0:'DNB', 1:'Dubstep', 2:'Grime', 3:'House', 4:'Reggae', 5:'Trap'}\n",
    "\n",
    "audio_extract = 'ffmpeg -i {} -vn -acodec pcm_s16le -ar 44100 -ac 2 {}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = torch.load(model_path)\n",
    "model_ft = model_ft.to(device)\n",
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Audio Files from Video Inputs\n",
    "files = os.listdir(file_path)\n",
    "for f in files:\n",
    "    os.system(audio_extract.format(file_path+f, runtime_path+f[:-3]+'wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate melspectrogram for audio files\n",
    "cmap = plt.get_cmap('inferno')\n",
    "files = os.listdir(runtime_path)\n",
    "for f in files:\n",
    "    if '.wav' in f:\n",
    "        songname = runtime_path + f\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(runtime_path+f[:-3]+'png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(runtime_path)\n",
    "\n",
    "for f in files:\n",
    "    if '.png' in f:\n",
    "        image = cv2.imread(runtime_path+f)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        image_tensor = test_transforms(image).float()\n",
    "        image_tensor = image_tensor.unsqueeze_(0)\n",
    "        input = Variable(image_tensor)\n",
    "        input = input.to(device)\n",
    "        output = model_ft(input)\n",
    "        index = output.data.cpu().numpy().argmax()\n",
    "        results_dict.update({f:genre_list[index]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_transparent(background, overlay, x, y):\n",
    "\n",
    "    background_width = background.shape[1]\n",
    "    background_height = background.shape[0]\n",
    "\n",
    "    if x >= background_width or y >= background_height:\n",
    "        return background\n",
    "\n",
    "    h, w = overlay.shape[0], overlay.shape[1]\n",
    "\n",
    "    if x + w > background_width:\n",
    "        w = background_width - x\n",
    "        overlay = overlay[:, :w]\n",
    "\n",
    "    if y + h > background_height:\n",
    "        h = background_height - y\n",
    "        overlay = overlay[:h]\n",
    "\n",
    "    if overlay.shape[2] < 4:\n",
    "        overlay = np.concatenate(\n",
    "            [\n",
    "                overlay,\n",
    "                np.ones((overlay.shape[0], overlay.shape[1], 1), dtype = overlay.dtype) * 255\n",
    "            ],\n",
    "            axis = 2,\n",
    "        )\n",
    "\n",
    "    overlay_image = overlay[..., :3]\n",
    "    mask = overlay[..., 3:] / 255.0\n",
    "\n",
    "    background[y:y+h, x:x+w] = (1.0 - mask) * background[y:y+h, x:x+w] + mask * overlay_image\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(file_path)\n",
    "playtrack = False\n",
    "for f in files:\n",
    "    time.sleep(1)\n",
    "    source = cv2.VideoCapture(file_path+f)\n",
    "    wave_obj = sa.WaveObject.from_wave_file(runtime_path+f[:-3]+'wav')\n",
    "    spectrogram = cv2.imread(runtime_path+f[:-3]+'png')\n",
    "    cv2.namedWindow(f, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(f, (960, 540))\n",
    "    while True:\n",
    "        ret, frame = source.read()\n",
    "        if ret:\n",
    "            frame = overlay_transparent(frame, spectrogram, 10, 90)\n",
    "            cv2.putText(frame, 'Melspectrogram', (10, 60), \n",
    "                cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'Genre: {}'.format(results_dict[f[:-3]+'png']), (10, 500), \n",
    "                cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            cv2.imshow(f, frame)\n",
    "            if not playtrack:\n",
    "                wave_obj.play()\n",
    "                playtrack = True\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "        if cv2.waitKey(18) & 0x0F == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    playtrack = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
